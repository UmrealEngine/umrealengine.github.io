---
layout: single
title: Web Crawler
tag: Web Crawler
author_profile: false
use_math: false
typora-root-url: ../
---

[^]: python ê¸°ì´ˆ DS

<h3 style="font-size: 8px; margin-top: -45px; font-color: #434343;">
  <a href="https://potettangeeeeeeeeeeeeeeeeeeeeeeeee.github.io/Python/" style="text-decoration: none; color: #3c3c3c; background-color: #f8f9fa; border-radius: 20px; padding: 5px 10px; display: inline-block;">
    <img src="../images/ImgFile/bf.png" style="height: 12.33px; width: auto; margin-top: -4px; vertical-align: middle;" alt="Python ì´ë¯¸ì§€">
    Python / Web crawler & Automation
  </a>
</h3>


<style>
  textarea {
    background-color: #272822;
    border: 2px solid #272822;
    border-radius: 4px;
    color: #ffffff;
    padding: 5px;
  }
  textarea:focus {
    border-color: #555;
    outline: none;
  }
  .code-wrapper {
    padding: 16px;
    border-radius: 8px;
  }
  u2 {
    text-decoration: underline;
    text-decoration-color: #ff0080;
    text-decoration-thickness: 3px;
  }
  u3 {
    text-decoration: underline;
    text-decoration-style: wavy;
    text-decoration-color: #ff0080;
    text-decoration-thickness: 3px;
  }
</style>





<br/>
<br/>

ğŸ“Œ **Web Crawer**

<br/>

```python
pip install request
```

```python
pip install bs4
```

í„°ë¯¸ë„ì„ ì—´ì–´ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

<br/>

<br/>

```python
import requests
from bs4 import BeautifulSoup
```

`import requests` == ì›¹ì‚¬ì´íŠ¸ ì ‘ì†ì„ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

`from bs4 import BeautifulSoup` ==  HTML ì›¹ë¬¸ì„œ ë¶„ì„ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬.

<br/>

<br/>

```python
import requests
from bs4 import BeautifulSoup

#data = requests.get("URL")
data = requests.get("https://www.upbit.com/trends")
print(data)
```

<pre>
&#60;Response [200]&#62;
</pre>

200 ëœ¨ë©´ ì •ìƒì ìœ¼ë¡œ ê°€ì ¸ì˜¨ê±°

<br/>

```python
print(data.status_code) 
```

ì›¹í˜ì´ì§€ì— ì œëŒ€ë¡œ ì ‘ì†ë˜ê³  ìˆëƒ ë¼ê³  ë¬¼ì–´ë³´ëŠ”ê±°, 

ì •ìƒ == 200

ë¹„ì •ìƒ == 400 or 500

<br/>

```python
print(data.content)
```

ì´ë ‡ê²Œ í•˜ë©´ html ë‹¤ ê¸ì–´ì˜¤ëŠ”ë° , ê¹¨ì ¸ì„œ ë³´ì´ëŠ” ë¬¸ì œê°€ ìˆìŒ

<br/>

<br/>

```python
import requests
from bs4 import BeautifulSoup

data = requests.get("https://www.upbit.com/trends")

bdata = BeautifulSoup(data.content, "html.parser") 
```

<u2>BeautifulSoup</u2> ì•ˆì— ë„£ì–´ì„œ ê¹”ë”í•˜ê²Œ ì •ë¦¬

<br/>

<br/>

<img src="../images/2023-04-30-Web Crawer (AP)/image-20230430162349079-1682841029052-2.png" align="left"><br/>

```python
#print(pdata.find_all("íƒœê·¸ëª…",ì†ì„±ëª…))

print(bdata.find_all("span",id="_quant"))
```

<pre>
[ &#60;span class="tah p11" id="_quant"&#62;18,139,558 &#60;/span&#62;]
</pre>

ì´ë ‡ê²Œí•˜ë©´ ì°¾ì€ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•´ì¤Œ

<br/>

```python
print(bdata.find_all("span",id="_quant")[0])
```

<pre>
&#60;span class="tah p11" id="_quant"&#62;18,139,558 &#60;/span&#62;
</pre>

ì´ë ‡ê²Œ í•´ì„œ ë¦¬ìŠ¤íŠ¸ ë²—ê¸°ê¸°ë„ ê°€ëŠ¥

<br/>

```python
print(bdata.find_all("span",id="_quant")[0].text)
```

<pre>
18,139,558
</pre>

í…ìŠ¤íŠ¸ë§Œ êº¼ë‚¼ ìˆ˜ ë„ ìˆìŒ

<br/>

<br/>


<img src="../images/2023-04-30-Web Crawer (AP)/image-20230430162349079-1682841029052-2.png" align="left"><br/>

ê·¼ë° ì´ì œ ë§Œì•½ idë§ê³  classë¡œ ì°¾ê³  ì‹¶ë‹¤ ?

```python
print(bdata.find_all("span",class_="tah")[0].text)
```

ì´ë ‡ê²Œ ì–¸ë”ë°” ì¶”ê°€í•´ ì¤˜ì•¼í•¨

ê·¸ë¦¬ê³  "tah p11" ì´ë ‡ê²Œ ë„ì–´ì¨ì ¸ìˆìœ¼ë©´ í´ë˜ìŠ¤ ëª…ì´ ë‘ê°œì¸ê±°

<br/>

íƒœê·¸ì— ë¶€ì—¬ëœ **id**ëŠ” **<u2>ìœ ë‹ˆí¬</u2>**

íƒœê·¸ì— ë¶€ì—¬ëœ **class**ëŠ” **<u2>ì¤‘ë³µ</u2>** ê°€ëŠ¥

<br/>
<br/>
<br/>

**<u3>í•˜ë‚˜ì”© í•´ì²´ë˜ì–´ ìˆì„ë–„</u3>**

![image-20230501141755997](/../../images/2023-04-30-Web Crawer (AP)/image-20230501141755997.png)

ì´ë ‡ê²Œ ê¸€ìê°€ í•˜ë‚˜ì”© í•´ì²´ë˜ì–´ ìˆì–´ë„

ê·¸ëƒ¥

```python
print(bdata.find_all("span",class_="no_up")[0].text)
```

ì¼ì¼€ í•˜ë©´ ë¨

<br/>

<br/>

**<u3>class, idê°€ ì—†ì„ë–„</u3>**

![image-20230501142129361](/../../images/2023-04-30-Web Crawer (AP)/image-20230501142129361.png)

```python
import requests
from bs4 import BeautifulSoup

#data = requests.get("URL")
data = requests.get("https://www.upbit.com/trends")

bdata = BeautifulSoup(data.content, "html.parser") 

print(bdata.find_all("span",id="_quant")[0])
```

<br/>

```python
print(bdata.find_all("em")[0])
```

ê·¸ëƒ¥ ì´ë ‡ê²Œ í•˜ë©´ ë˜ëŠ”ë° ê·¸ëŸ¼ emì´ ë„ˆë¬´ ë§ìŒ

<br/>

```python
bdata.select(".f_up")
```

`class = "f_up"` ì„ ì°¾ëŠ” ì½”ë“œ

classë¥¼ ì°¾ì„ë–„ëŠ” **<u2>.</u2>**

<br/>

```python
bdata.select("#f_up")
```

idë¥¼ ì°¾ì„ë–„ëŠ” **<u2>#</u2>**

ê·¼ë° ì´ëŒ€ë¡œëŠ” ì´ ì „ì— í–ˆë˜ê²ƒ ë³´ë‹¤ëŠ” ìì„¸í•œê²Œ ì•„ë‹˜ 

```python
print(bdata.find_all("span",id="_quant")[0].text)
```

ì´ ì½”ë“œì™€ ë˜‘ê°™ì´ í• ë ¤ë©´ 

```python
bdata.select("span#f_up")
```

<br/>

```python
bdata.select("span")
```

```python
bdata.select("td")
```

ì•„ë¬´ê²ƒë„ ì—†ì´ ì“°ë©´ íƒœê·¸ëª… ê²€ìƒ‰

<br/>

![image-20230501142129361](/../../images/2023-04-30-Web Crawer (AP)/image-20230501142129361.png)

```python
bdata.select(".f_up em")
```

ë„ì–´ì“°ê¸°ëŠ” ë‚´ë¶€ìš”ì†Œë¥¼ ì°¾ì„ë•Œ

`.f_up`ì•ˆì— ìˆëŠ” `em`ì„ ì°¾ì•„ë¼

<br/>

+

```python
bdata.select(".f_up em")[0].txt
```

<br/>

<br/>

**<u3>ì´ë¯¸ì§€ ìˆ˜ì§‘ í•˜ê¸°</u3>**

![image-20230501144109355](/../../images/2023-04-30-Web Crawer (AP)/image-20230501144109355.png)

```python
testimage = bdata.select("#imh_chart_area")
print(testimage)
```

<pre>
[&#60;img alt="ì´ë¯¸ì§€ ì°¨íŠ¸" height="289" id="img_chart_area" onerror="this.src='https://ssl.pstatic.net/imgstock/chart3/world2008/error_700x289.png'" src="https://ssl.pstatic.net/imgfinance/chart/item/area/day/005930.png?sidcode=1682919827505" width="700"/	&#62;]
</pre>

<br/>

```python
testimage = bdata.select("#imh_chart_area")[0]
print(testimage)
```

<pre>
&#60;img alt="ì´ë¯¸ì§€ ì°¨íŠ¸" height="289" id="img_chart_area" onerror="this.src='https://ssl.pstatic.net/imgstock/chart3/world2008/error_700x289.png'" src="https://ssl.pstatic.net/imgfinance/chart/item/area/day/005930.png?sidcode=1682919827505" width="700"/	&#62;
</pre>

<br/>

ì´ë¯¸ì§€ ìì²´ë§Œ ì¶”ì¶œí•˜ê³  ì‹¶ìœ¼ë©´ 

```python
testimage = bdata.select("#imh_chart_area")[0]

print(testimage["src"])
```

<pre>
https://ssl.pstatic.net/imgfinance/chart/item/area/day/005930.png?sidcode=1682919993247
</pre>

<br/>

<br/>

<br/>

**<u3>ì´ë¯¸ì§€ URLì„ ê°€ì§€ê³  íŒŒì¼ë¡œ ì €ì¥ í•˜ëŠ” ë°©ë²•</u3>**

```python
import requests             #<-------- ì´ ì½”ë“œ ì¶”ê°€
import urllib.request
from bs4 import BeautifulSoup


data = requests.get("https://www.upbit.com/trends")

bdata = BeautifulSoup(data.content, "html.parser") 

testimage = bdata.select("#img_chart_area")[0]

# urllib.request.urlretrieve("ì´ë¯¸ì§€URL", 'íŒŒì¼ëª…')     <----------- ì¶”ê°€

urllib.request.urlretrieve("https://ssl.pstatic.net/imgfinance/chart/item/area/day/005930.png?sidcode=1682919993247", "Chart.png")
```

<br/>

<br/>

<br/>

ğŸš€ **for / def**

```python
testlist = ["ê°€", "ë‚˜", "ë‹¤", "ë¼",]

for i in range(4)
	print(i)
```

ì´ê±°ë‘ ë°‘ì—ë‘ ë˜‘ê°™ìŒ 

```python
for i in testlist:       #<----- ì´ë ‡ê²Œ ë°”ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì„ ìˆ˜ ìˆìŒ
    print(i)             #<----- iê°€ 1,2,3,4 ì´ë ‡ê²Œ ë³€í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ ê°€, ë‚˜ , ë‹¤ ,ë¼ ì´ë ‡ê²Œ ë³€í•¨ 
```

<br/>

<br/>

<br/>

ğŸ“Œ **ë¬´í•œ ìŠ¤í¬ë¡¤ ë°ì´í„° ìˆ˜ì§‘(NAVER)**

<br/>

ì¼ë°˜ ì ìœ¼ë¡œ pageë¡œ ë‚˜ë‰˜ëŠ” ì‚¬ì´íŠ¸ëŠ” page{ë²ˆí˜¸} ë§Œ ë°”ê¿”ì£¼ë©´ ì†ì‰½ê²Œ ê°€ëŠ¥

ì´ëŸ°ê±° ë§ê³ 

**<u2>ë„¤ì´ë²„ ê²€ìƒ‰ -> view</u2>**  ì²˜ëŸ¼ ë¬´í•œìŠ¤í¬ë¡¤ í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ í•˜ëŠ” ë²•

![image-20230501154518622](/../../images/2023-05-01-Web Crawer 2/image-20230501154518622.png)

```python
import requests            
from bs4 import BeautifulSoup


requests.get("https://s.search.naver.com/p/review/search.naver?rev=44&where=view&api_type=11&start=31&query=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC&nso=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22food_recipe%22%7D%7D%7D&main_q=&mode=normal&q_material=&ac=1&aq=0&spq=0&st_coll=&topic_r_cat=&nx_search_query=&nx_and_query=&nx_sub_query=&prank=31&sm=tab_jum&ssc=tab.view.view&ngn_country=KR&lgl_rcode=03121129&fgn_region=&fgn_city=&lgl_lat=35.2416&lgl_long=128.6265&abt=&_callback=viewMoreContents")

requests.get("https://s.search.naver.com/p/review/search.naver?rev=44&where=view&api_type=11&start=61&query=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC&nso=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22food_recipe%22%7D%7D%7D&main_q=&mode=normal&q_material=&ac=1&aq=0&spq=0&st_coll=&topic_r_cat=&nx_search_query=&nx_and_query=&nx_sub_query=&prank=31&sm=tab_jum&ssc=tab.view.view&ngn_country=KR&lgl_rcode=03121129&fgn_region=&fgn_city=&lgl_lat=35.2416&lgl_long=128.6265&abt=&_callback=viewMoreContents")
```

<br/>

![image-20230501154740878](/../../images/2023-05-01-Web Crawer 2/image-20230501154740878.png)

ì´ë ‡ê²Œ ê·œì¹™ì„ íŒŒì•…í•˜ë©´ ë°ì´í„° ìˆ˜ì§‘ í¸í•˜ê²Œ ê°€ëŠ¥

<br/>

<br/>

**<u3>ì œëª©ë§Œ ë½‘ì•„ë³´ê¸°</u3>**

```python
import requests            
from bs4 import BeautifulSoup


data = requests.get("https://s.search.naver.com/p/review/search.naver?rev=44&where=view&api_type=11&start=31&query=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC&nso=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22food_recipe%22%7D%7D%7D&main_q=&mode=normal&q_material=&ac=1&aq=0&spq=0&st_coll=&topic_r_cat=&nx_search_query=&nx_and_query=&nx_sub_query=&prank=31&sm=tab_jum&ssc=tab.view.view&ngn_country=KR&lgl_rcode=03121129&fgn_region=&fgn_city=&lgl_lat=35.2416&lgl_long=128.6265&abt=&_callback=viewMoreContents")

a = BeautifulSoup(data.content, "html.parser")

print(a)
```

ì´ë ‡ê²Œë§Œ í•˜ë©´ ì¶œë ¥ë¬¼ì— `\` ì´ê²Œ ë“¤ì–´ ìˆìŒ ,  ë°ì´í„° ì „ì†¡ì„ ìœ„í•´ ê°€ë” ìˆëŠ”ë° ì´ê±¸ ì§€ì›Œì¤˜ì•¼í•¨

```python
# a = BeautifulSoup(data.content.replace("ì´ê±°ë¥¼", "ì´ê±°ë¡œ ë°”ê¿”ì£¼ì„¸ìš”") "html.parser")

a = BeautifulSoup(data.content.replace("\\", ""),"html.parser")
```

<pre>
Error
</pre>

replaceë¥¼ ì“¸ë ¤ë©´ ì™¼ìª½ì´ textì—¬ì•¼í•¨

contentëŠ” ë­ë¼ê³  ì•Œë´ì¤¬ëŠ”ë°  ê¹Œë¨¹ìŒ ã…‹

```python
a = BeautifulSoup(data.text.replace("\\", ""),"html.parser")
```

<br/>

```python
a = BeautifulSoup(data.text.replace("\\", "") "html.parser")

print(a.select("a.api_text_lines"))     #<------ findall ì¨ë„ ã„±ã…Š ìê¸° ì„ íƒ
```

<br/>

```python
import requests            
from bs4 import BeautifulSoup


data = requests.get("https://s.search.naver.com/p/review/search.naver?rev=44&where=view&api_type=11&start=31&query=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC&nso=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22food_recipe%22%7D%7D%7D&main_q=&mode=normal&q_material=&ac=1&aq=0&spq=0&st_coll=&topic_r_cat=&nx_search_query=&nx_and_query=&nx_sub_query=&prank=31&sm=tab_jum&ssc=tab.view.view&ngn_country=KR&lgl_rcode=03121129&fgn_region=&fgn_city=&lgl_lat=35.2416&lgl_long=128.6265&abt=&_callback=viewMoreContents")

a = BeautifulSoup(data.text.replace("\\", ""), "html.parser")

b = a.select("a.api_txt_lines")

print(b[0].text)
print(b[1].text)
print(b[2].text)
```

<pre>
í™ˆì¹´í˜ ë ˆì‹œí”¼, ì•„ì´ìŠ¤í¬ë¦¼ ë¼ë–¼ ë§Œë“¤ê¸° (w. ê°€ì°Œì•„ ì•„ë‹ˆë§ˆ)
ì†”í‹°ë“œë°”ë‹ë¼/ë„¤ì¶”ëŸ´í‚¹ë¤ ê³ êµ¬ë§ˆíë¸Œ/ë¨¸ë“œìŠ¤ì½˜ ë§ì´ˆì¹©/ì–´ë¥¸ì´ë‚  ë„ë‹´ ëš±ì¹´ë¡±/ë©”
ê°€ì»¤í”¼ ë¡œíˆ¬ìŠ¤ì•„ì´ìŠ¤í¬ë¦¼
í•˜ë™ì•…ì–‘ëŒ€ë´‰ê³¶ê° ì•„ì´ìŠ¤í¬ì¥ìœ¼ë¡œ ë“ ë“ íˆ~ ë¶€ëª¨ë‹˜ ê°„ì‹ìœ¼ë¡œ ì•„ì´ë“¤ ì²œì—°ì•„ì´ìŠ¤í¬
ë¦¼ìœ¼ë¡œ ì‹œì› ë‹¬ì½¤í•œ ë§›...
</pre>

<br/>

<br/>

**<u3>URLë„ ë½‘ì•„ë³´ê¸°</u3>**

![image-20230501161523845](/../../images/2023-05-01-Web Crawer 2/image-20230501161523845.png)

ë³´ë‹ˆê¹  `a`íƒœê·¸ì— ê°™ì´ ë“¤ì–´ ìˆìŒ

```python
print(b[0]["href"])
print(b[1]["href"])
print(b[2]["href"])
```

<pre>
https://blog.naver.com/murum4/223045209324
https://blog.naver.com/jtu0323/223088325622
https://blog.naver.com/hhk520/223063509751
</pre>

<br/>

<br/>